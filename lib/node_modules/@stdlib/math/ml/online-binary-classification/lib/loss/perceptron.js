'use strict';

// MODULES //

var regularize = require( './../regularize.js' );


// MAIN //

/**
* Given a new observation `(x,y)`, updates the weights using the perceptron loss.
*
* #### Notes
*
* * The perceptron loss is equal to the hinge loss without a margin
* * The perceptron loss will not update model parameters when the response is correctly classified
*
* @private
* @param {WeightVector} weights - current model coefficients
* @param {NumericArray} x - feature vector
* @param {number} y - response value
* @param {PositiveNumber} eta - current learning rate
* @param {NonNegativeNumber} lambda - regularization parameter
*/
function perceptron( weights, x, y, eta, lambda ) {
	var z = weights.innerProduct( x );

	// Perform L2 regularization...
	regularize( weights, lambda, eta );

	if ( y * z <= 0 ) {
		weights.add( x, ( eta * y ) );
	}
} // end FUNCTION perceptron()


// EXPORTS //

module.exports = perceptron;
