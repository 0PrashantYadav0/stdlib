Online Regression
===

> Online regression via Stochastic Gradient Descent


<!-- <usage> -->

## Usage

``` javascript
var OnlineSGDRegression = require( '@stdlib/math/ml/online-sgd-regression' );
```

#### OnlineSGDRegression( \[options\] )

Creates an online linear regression model fitted via stochastic gradient descent. The module performs L2 regularization of the model coefficients, shrinking them towards zero by penalizing the squared euclidean norm of the coefficients.

``` javascript
var model = new OnlineSGDRegression();

// Data comes in...
for ( i = 0; i < 100000; i++ ) {
	x1 = Math.random();
	x2 = Math.random();
	y = 3.0 * x1 + -3.0 * x2 + 2.0;
	model.update( y, [ x1, x2 ] );
}

// Show model coefficients:
console.log( model.coefs )
```

The function accepts the following `options`:

* __learningRate__: `string` denoting the learning rate to use. Can be `constant`, `pegasos` or `basic`. Default: `pegasos`.
* __loss__: `string` denoting the loss function to use. Can be `leastSquares`, `epsilonInsensitive` or `huber`. Default: `epsilonInsensitive`.
* __epsilon__: insensitivity parameter. Default: `0.1`.
* __lambda__: regularization parameter. Default: `1e-3`.
* __eta0__: constant learning rate. Default: `0.02`.
* __intercept__: `boolean` indicating whether to include an intercept. Default: `true`.

The `learningRate` decides how fast or slow the weights will be updated towards the optimal weights. Let `it` denote the current iteration of the algorithm (i.e. the number of data points having arrived). The possible learning rates are:

| Option       | Definition             |
|:------------:|:----------------------:|
| pegasos      |  1.0 / ( lambda * it ) |
| basic        |  10.0 / ( it + 10 )    |
| constant     | sets debug mode        |

By default, `pegasos` is used.

The used loss function is specified via the `loss` option. By default, the epsilon-insensitive loss is used. The available options are:

| Option             | Description             |
|:------------------:|:----------------------:|
| epsilonInsensitive | Penalty is the absolute value of the error whenever the absolute error exceeds epsilon and zero otherwise |
| huber              | Squared-error loss for observations with error smaller than epsilon in magnitude, linear loss otherwise. Should be used in order to decrease the influence of outliers on the model fit |
| leastSquares       | Squared error loss, i.e. the squared difference of the observed and fitted values |

Instances of `OnlineSGDRegression` expose the following methods and properties:

#### model.update( y, x )

Update the model coefficients in light of incoming data. `y` has to be a numeric response value, `x` an `numeric array` of predictors. The number of predictors is decided upon first invocation of this method. All subsequent calls must supply `x` vectors of the same dimensionality.

``` javascript
model.update( 5.0, [ 1.0, 0.0 ] );
```

#### model.predict( x )

Predict the response for a new observation with features given by `x`, where `x` has to be a `numeric array` of predictors.

``` javascript
var yhat = model.predict( [ 0.5, 2.0 ] );
// returns <number>
```

#### model.coefs

Getter for the model coefficients / feature weights stored in an `array`.

``` javascript
var coefs = model.coefs;
// returns <array>
```

<!-- </usage> -->

<!-- <examples> -->

## Examples

``` javascript
var OnlineSGDRegression = require( '@stdlib/math/ml/online-sgd-regression' );
var x1;
var x2;
var y;
var i;

// Create model:
var model = new OnlineSGDRegression({
	'lambda': 1e-4,
	'loss': 'leastSquares',
	'intercept': true
});

// Data comes in...
for ( i = 0; i < 100000; i++ ) {
	x1 = Math.random();
	x2 = Math.random();
	y = 3.0 * x1 + -3.0 * x2 + 2.0;
	model.update( y, [ x1, x2 ] );
}

// Extract model coefficients:
console.log( model.coefs );

// Predict new observations:
console.log( 'y_hat = %d; x1 = %d; x2 = %d', model.predict( [0.9,0.1] ), 0.9, 0.1 );
console.log( 'y_hat = %d; x1 = %d; x2 = %d', model.predict( [0.1,0.9] ), 0.1, 0.9 );
console.log( 'y_hat = %d; x1 = %d; x2 = %d', model.predict( [0.9,0.9] ), 0.9, 0.9 );
```

<!-- </examples> -->


<!-- <links> -->

<!-- </links> -->
