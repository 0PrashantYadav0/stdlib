'use strict';

// MODULES //

var isArray = require( '@stdlib/utils/is-array' );
var copy = require( '@stdlib/utils/copy' );
var WeightVector = require( './weight_vector.js' );
var epsilonInsensitiveLoss = require( './loss/epsilon_insensitive.js' );
var leastSquaresLoss = require( './loss/least_squares.js' );
var huberLoss = require( './loss/huber.js' );
var DEFAULTS = require( './defaults.json' );
var validate = require( './validate.js' );


// CONSTANTS //

var MIN_SCALING_FACTOR = 1e-7;


// FUNCTIONS //

var max = Math.max;

/**
* L2 regularization of feature weights.
*
* @private
* @param {WeightVector} weights - current model coefficients
* @param {PositiveNumber} lambda - regularization parameter
* @param {PositiveNumber} eta - current learning rate
*/
function regularize( weights, lambda, eta ) {
	var scalingFactor = 1.0 - ( eta * lambda );
	weights.scaleTo( max( scalingFactor, MIN_SCALING_FACTOR ) );
} // end FUNCTION regularize()


// ONLINE SGD REGRESSION //

/**
* Online learning for regression using stochastic gradient descent (SGD).
*
* #### Method
*
* The sub-gradient of the loss function is estimated for each datum and the regression model is updated incrementally, with a decreasing learning rate and regularization of the feature weights based on L2 regularization.
*
* Reference:
* * Shalev-Shwartz, S., Singer, Y., Srebro, N., & Cotter, A. (2011). Pegasos: Primal estimated sub-gradient solver for SVM. Mathematical Programming, 127(1), 3â€“30. doi:10.1007/s10107-010-0420-4
*
* @constructor
* @param {Object} [options] - options object
* @param {PositiveNumber} [options.epsilon=0.1] - insensitivity parameter
* @param {PositiveNumber} [options.eta0=0.02] - constant learning rate
* @param {PositiveNumber} [options.lambda=1e-3] - regularization parameter
* @param {string} [options.learningRate='basic'] - string denoting the learning rate to use. Can be `constant`, `pegasos` or `basic`.
* @param {string} [options.loss='leastSquares'] - string denoting the loss function to use. Can be `leastSquares`, `epsilonInsensitive` or `huber`.
* @param {boolean} [options.intercept=true] - boolean indicating whether to include an intercept
* @throws {TypeError} must provide valid options
* @returns {OnlineSGDRegression} class instance
*
* @example
* var OnlineSGDRegression = require( '@stdlib/streams/math/ml/online-sgd-regression' );
*
* var model = OnlineSGDRegression({
* 	'intercept': true
* 	'lambda': 1e-5
* });
*
* // Update model as observations come in:
* var y = 3.5;
* var x = [ 2.3, 1.0, 5.0 ];
* model.update( y, x );
*
* // Predict new observation:
* var yHat = model.predict( x );
*
* // Retrieve coefficients:
* var coefs = model.coefs;
*/
function OnlineSGDRegression( options ) {
	var opts;
	var err;
	if ( !(this instanceof OnlineSGDRegression) ) {
		return options ? new OnlineSGDRegression( options ) : new OnlineSGDRegression();
	}
	opts = copy( DEFAULTS );
	if ( arguments.length > 0 ) {
		err = validate( opts, options );
		if ( err ) {
			throw err;
		}
	}
	this.weights = null;
	// Initialize counter:
	this.it = 1;

	// Set loss function:
	switch ( opts.loss ) {
	case 'epsilonInsensitive':
		this._lossfun = epsilonInsensitiveLoss;
	break;
	case 'huber':
		this._lossfun = huberLoss;
	break;
	case 'leastSquares':
		this._lossfun = leastSquaresLoss;
	break;
	default:
		throw Error( 'invalid input value. `loss` option must be either `epsilonInsensitive`, `huber` or `leastSquares`. Value: `' + opts.loss + '`' );
	}

	// Set learning rate:
	switch ( opts.learningRate ) {
	case 'basic':
		// Default case: 'basic'
		this.getEta = function getEta() {
			return 1000.0 / ( this.it + 1000.0 );
		};
	break;
	case 'constant':
		this.getEta = function getEta() {
			return opts.eta0;
		};
	break;
	case 'pegasos':
		this.getEta = function getEta() {
			return 1.0 / ( opts.lambda * this.it );
		};
	break;
	default:
		throw Error( 'invalid input value. `learningRate` option must be either `basic`, `constant` or `pegasos`. Value: `' + opts.learningRate + '`' );
	}

	// Define coefficient getter:
	Object.defineProperty( this, 'coefs', {
		get: function getCoefs() {
			var ret;
			var i;

			ret = new Array( this.weights.nWeights );
			for ( i = 0; i < ret.length; i++ ) {
				ret[ i ] = this.weights._data[ i ] * this.weights.scale;
			}
			return ret;
		}
	});

	/**
	* Update weights given new observations `y` and `x`.
	*
	* @param {NumericArray} x - feature vector
	* @param {number} y - response value
	*/
	this.update = function update( x, y ) {
		var eta;

		if ( !this.weights ) {
			this.weights = new WeightVector( x.length, opts.intercept );
			this.nFeatures = opts.intercept ? this.weights.nWeights - 1 : this.weights.nWeights;
		}

		if ( !isArray( x ) || x.length !== this.nFeatures ) {
			throw new TypeError( 'invalid input value. Second argument `x` must be an array of length ' + this.nFeatures + '. Value: `' + x + '`' );
		}

		// Get current learning rate...
		eta = this.getEta();

		// Perform L2 regularization...
		regularize( this.weights, opts.lambda, eta );

		// Update weights depending on the chosen loss function...
		this._lossfun( this.weights, y, x, eta, opts.epsilon );

		// Increase iteration counter...
		this.it += 1;
	}; // end METHOD _updateWithoutIntercept()

	/**
	* Predict response for a new observation with features `x`.
	*
	* @param {NumericArray} x - feature vector
	* @returns {number} response value
	*/
	this.predict = function predict( x ) {
		if ( !isArray( x ) || x.length !== this.nFeatures ) {
			throw new TypeError( 'invalid input value. First rgument `x` must be an array of length ' + this.nFeatures + '. Value: `' + x + '`' );
		}
		return this.weights.innerProduct( x );
	}; // end METHOD predict()
} // end FUNCTION OnlineSGDRegression()


// EXPORTS //

module.exports = OnlineSGDRegression;
