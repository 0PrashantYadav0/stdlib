'use strict';

var getSpeeches = require( '@stdlib/datasets/sotu' );
var roundn = require( '@stdlib/math/base/special/roundn' );
var STOPWORDS = require( '@stdlib/datasets/stopwords-english' );
var lda = require( './../lib' );

var speeches;
var terms;
var model;
var str;
var i;

speeches = getSpeeches({
	range: [ 1930, 2010 ]
}).map( function getText( e ) {
	str = e.text.toLowerCase();
	STOPWORDS.forEach( function removeIt( word ) {
		var RE = new RegExp( '\\b' + word + '\\b', 'gi' );
		str = str.replace( RE, '' );
	});
	return str;
});

model = lda( speeches, 3 );

model.fit( 1000, 100, 10 );

for ( i = 0; i <= 80; i++ ) {
	str = 'Year: ' + (1930+i) + '\t';
	str += 'Topic 1: ' + roundn( model.avgTheta.get( i, 0 ), -3 ) + '\t';
	str += 'Topic 2: ' + roundn( model.avgTheta.get( i, 1 ), -3 ) + '\t';
	str += 'Topic 3: ' + roundn( model.avgTheta.get( i, 2 ), -3 );
	console.log( str );
}

terms = model.getTerms( 0, 20 );
for ( i = 0; i < terms.length; i++ ) {
	terms[ i ] = terms[ i ].word;
}
console.log( 'Words most associated with first topic:\n ' + terms.join( ', ' ) );

terms = model.getTerms( 1, 20 );
for ( i = 0; i < terms.length; i++ ) {
	terms[ i ] = terms[ i ].word;
}
console.log( 'Words most associated with second topic:\n ' + terms.join( ', ' ) );

terms = model.getTerms( 2, 20 );
for ( i = 0; i < terms.length; i++ ) {
	terms[ i ] = terms[ i ].word;
}
console.log( 'Words most associated with third topic:\n ' + terms.join( ', ' ) );
