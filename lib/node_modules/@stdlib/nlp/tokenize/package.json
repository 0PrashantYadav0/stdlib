{
  "name": "",
  "version": "",
  "description": "Tokenize a string.",
  "author": {},
  "contributors": [],
  "scripts": {},
  "main": "./lib",
  "repository": {},
  "keywords": [
    "stdlib",
    "nlp",
    "utilities",
    "utility",
    "utils",
    "util",
    "text mining",
    "tokenizer",
    "split",
    "separate",
    "tokens",
    "word"
  ],
  "bugs": {},
  "dependencies": {},
  "devDependencies": {},
  "license": ""
}
