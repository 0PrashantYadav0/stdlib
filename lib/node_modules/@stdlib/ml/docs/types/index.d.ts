/*
* @license Apache-2.0
*
* Copyright (c) 2021 The Stdlib Authors.
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*    http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

// TypeScript Version: 2.0

/* tslint:disable:max-line-length */
/* tslint:disable:max-file-line-count */

import incr = require( '@stdlib/ml/incr' );
import onlineBinaryClassification = require( '@stdlib/ml/online-binary-classification' );
import onlineSGDRegression = require( '@stdlib/ml/online-sgd-regression' );

/**
* Interface describing the `ml` namespace.
*/
interface Namespace {
	/**
	* Standard library incremental machine learning algorithms.
	*/
	incr: typeof incr;

	/**
	* Online learning for classification using stochastic gradient descent (SGD).
	*
	* ## Method
	*
	* The sub-gradient of the loss function is estimated for each datum and the classification model is updated incrementally, with a decreasing learning rate and regularization of the feature weights based on L2 regularization.
	*
	* ## References
	*
	* -   Shalev-Shwartz, S., Singer, Y., Srebro, N., & Cotter, A. (2011). Pegasos: Primal estimated sub-gradient solver for SVM. Mathematical Programming, 127(1), 3–30. doi:10.1007/s10107-010-0420-4
	*
	* @param options - options object
	* @param options.epsilon - insensitivity parameter (default: 0.1)
	* @param options.eta0 - constant learning rate (default: 0.02)
	* @param options.lambda - regularization parameter (default: 1e-3)
	* @param options.learningRate - string denoting the learning rate to use. Can be `constant`, `pegasos`, or `basic` (default: 'basic')
	* @param options.loss - string denoting the loss function to use. Can be `hinge`, `log`, `modifiedHuber`, `perceptron`, or `squaredHinge` (default: 'log')
	* @param options.intercept - boolean indicating whether to include an intercept (default: true)
	* @throws must provide valid options
	* @returns classification model
	*
	* @example
	* var ns.onlineBinaryClassification = require( `@stdlib/streams/ml/online-sgd-classification` );
	*
	* var model = ns.onlineBinaryClassification({
	*    'intercept': true
	*    'lambda': 1e-5
	* });
	*
	* // Update model as observations come in:
	* var y = -1;
	* var x = [ 2.3, 1.0, 5.0 ];
	* model.update( x, y );
	*
	* // Predict new observation:
	* var yHat = model.predict( x );
	*
	* // Retrieve coefficients:
	* var coefs = model.coefs;
	*/
	onlineBinaryClassification: typeof onlineBinaryClassification;

	/**
	* Online learning for regression using stochastic gradient descent (SGD).
	*
	* ## Method
	*
	* The sub-gradient of the loss function is estimated for each datum and the regression model is updated incrementally, with a decreasing learning rate and regularization of the feature weights based on L2 regularization.
	*
	* ## References
	*
	* -   Shalev-Shwartz, S., Singer, Y., Srebro, N., & Cotter, A. (2011). Pegasos: Primal estimated sub-gradient solver for SVM. Mathematical Programming, 127(1), 3–30. doi:10.1007/s10107-010-0420-4
	*
	* @param options - options object
	* @param options.epsilon - insensitivity parameter (default: 0.1)
	* @param options.eta0 - constant learning rate (default: 0.02)
	* @param options.lambda - regularization parameter (default: 1e-3)
	* @param options.learningRate - string denoting the learning rate to use. Can be `constant`, `pegasos`, or `basic` (default: 'basic')
	* @param options.loss - string denoting the loss function to use. Can be `squaredError`, `epsilonInsensitive`, or `huber` (default: 'squaredError')
	* @param options.intercept - boolean indicating whether to include an intercept (default: true)
	* @throws must provide valid options
	* @returns regression model
	*
	* @example
	* var ns.onlineSGDRegression = require( `@stdlib/streams/ml/online-sgd-regression` );
	*
	* var model = ns.onlineSGDRegression({
	*     'intercept': true
	*     'lambda': 1e-5
	* });
	*
	* // Update model as observations come in:
	* var y = 3.5;
	* var x = [ 2.3, 1.0, 5.0 ];
	* model.update( x, y );
	*
	* // Predict new observation:
	* var yHat = model.predict( x );
	*
	* // Retrieve coefficients:
	* var coefs = model.coefs;
	*/
	onlineSGDRegression: typeof onlineSGDRegression;
}

/**
* Standard library machine learning algorithms.
*/
declare var ns: Namespace;


// EXPORTS //

export = ns;
